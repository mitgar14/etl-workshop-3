{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***World Happiness Report - Model Training and Metrics***\n",
    "---\n",
    "In this notebook, we will carry out the training of a Machine Learning model using the World Happiness Report dataset. This process will include several key steps, such as **Data Preprocessing**, **Dataset Splitting** and **Model Selection and Training**. Finally, we will interpret the obtained results in the next notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Setting the notebook**\n",
    "\n",
    "First we will adjust the directory of our project in order to correctly detect the packages and modules that we are going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    os.chdir(\"../../etl-workshop-3\")\n",
    "except FileNotFoundError:\n",
    "    print(\"You are already in the correct directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceed to import the following for this notebook:\n",
    "\n",
    "### **Dependencies**\n",
    "\n",
    "* **Pandas** ➜ Used for data manipulation and analysis.\n",
    "\n",
    "* **scikit-learn** ➜ Used for machine learning, providing simple and efficient tools for data analysis.\n",
    "    \n",
    "    * *model_selection.train_test_split* ➜ Splits datasets into random train and test subsets for training and evaluating models.\n",
    "\n",
    "    * *linear_model.LinealRegression* ➜ Implements ordinary least squares linear regression.\n",
    "\n",
    "    * *ensemble.RandomForestRegressor* ➜ Implements a random forest regressor to improve predictive accuracy.\n",
    "\n",
    "    * *ensemble.GradientBoostingRegressor* ➜ Implements gradient boosting regression to enhance accuracy by combining weak models.\n",
    "\n",
    "    * *metrics.mean_squared_error* ➜ Calculates the mean squared error, a metric to evaluate the quality of predictions.\n",
    "\n",
    "    * *metrics.r2_score* ➜ Calculates the R² coefficient of determination to measure model fit.\n",
    "\n",
    "* **joblib** ➜ Library for serializing and deserializing Python objects, useful for saving and loading trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Reading the data**\n",
    "\n",
    "We load the CSV generated in the first notebook (*01-EDA*) after performing transformations and merging the 5 datasets from the World Happiness Report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/world_happiness_report.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>continent</th>\n",
       "      <th>year</th>\n",
       "      <th>economy</th>\n",
       "      <th>health</th>\n",
       "      <th>social_support</th>\n",
       "      <th>freedom</th>\n",
       "      <th>corruption_perception</th>\n",
       "      <th>generosity</th>\n",
       "      <th>happiness_rank</th>\n",
       "      <th>happiness_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.39651</td>\n",
       "      <td>0.94143</td>\n",
       "      <td>1.34951</td>\n",
       "      <td>0.66557</td>\n",
       "      <td>0.41978</td>\n",
       "      <td>0.29678</td>\n",
       "      <td>1</td>\n",
       "      <td>7.587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.30232</td>\n",
       "      <td>0.94784</td>\n",
       "      <td>1.40223</td>\n",
       "      <td>0.62877</td>\n",
       "      <td>0.14145</td>\n",
       "      <td>0.43630</td>\n",
       "      <td>2</td>\n",
       "      <td>7.561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.32548</td>\n",
       "      <td>0.87464</td>\n",
       "      <td>1.36058</td>\n",
       "      <td>0.64938</td>\n",
       "      <td>0.48357</td>\n",
       "      <td>0.34139</td>\n",
       "      <td>3</td>\n",
       "      <td>7.527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Norway</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.45900</td>\n",
       "      <td>0.88521</td>\n",
       "      <td>1.33095</td>\n",
       "      <td>0.66973</td>\n",
       "      <td>0.36503</td>\n",
       "      <td>0.34699</td>\n",
       "      <td>4</td>\n",
       "      <td>7.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canada</td>\n",
       "      <td>North America</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.32629</td>\n",
       "      <td>0.90563</td>\n",
       "      <td>1.32261</td>\n",
       "      <td>0.63297</td>\n",
       "      <td>0.32957</td>\n",
       "      <td>0.45811</td>\n",
       "      <td>5</td>\n",
       "      <td>7.427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country      continent  year  economy   health  social_support  \\\n",
       "0  Switzerland         Europe  2015  1.39651  0.94143         1.34951   \n",
       "1      Iceland         Europe  2015  1.30232  0.94784         1.40223   \n",
       "2      Denmark         Europe  2015  1.32548  0.87464         1.36058   \n",
       "3       Norway         Europe  2015  1.45900  0.88521         1.33095   \n",
       "4       Canada  North America  2015  1.32629  0.90563         1.32261   \n",
       "\n",
       "   freedom  corruption_perception  generosity  happiness_rank  happiness_score  \n",
       "0  0.66557                0.41978     0.29678               1            7.587  \n",
       "1  0.62877                0.14145     0.43630               2            7.561  \n",
       "2  0.64938                0.48357     0.34139               3            7.527  \n",
       "3  0.66973                0.36503     0.34699               4            7.522  \n",
       "4  0.63297                0.32957     0.45811               5            7.427  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Data preprocessing and splitting***\n",
    "\n",
    "In this section, we perform data preprocessing and split the data into training and testing sets using the functions `creating_dummy_variables` and `train_test_split`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Getting dummy values for categorical columns**\n",
    "First, we convert the `continent` column into dummy variables. This process is quite necessary, since the model would be unable to observe the trends of this variable if it were a column composed of text (categories), it is necessary to translate this categorization into a numerical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_dummy_variables(df):\n",
    "    df = pd.get_dummies(df, columns=[\"continent\"])\n",
    "    \n",
    "    columns_rename = {\n",
    "        \"continent_North America\": \"continent_North_America\",\n",
    "        \"continent_Central America\": \"continent_Central_America\",\n",
    "        \"continent_South America\": \"continent_South_America\"\n",
    "    }\n",
    "\n",
    "    df = df.rename(columns=columns_rename)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = creating_dummy_variables(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Splitting data**\n",
    "\n",
    "Now, we split the data into training and testing sets using the sklearn function `train_test_split`. First, we need to remove certain columns that would not benefit our model, which are:\n",
    "\n",
    "* *happiness_score* ➜ This is the target variable.\n",
    "\n",
    "* *happiness_rank* ➜ It has an inverse correlation with the target variable; including it would only confuse the model.\n",
    "\n",
    "* *country* ➜ The large amount of categorical data it contains would make the training process too heavy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"happiness_score\", \"happiness_rank\", \"country\"], axis = 1)\n",
    "y = df[\"happiness_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (547, 14)\n",
      "Test data shape:  (235, 14)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data shape: \", X_train.shape)\n",
    "print(\"Test data shape: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'economy', 'health', 'social_support', 'freedom',\n",
       "       'corruption_perception', 'generosity', 'continent_Africa',\n",
       "       'continent_Asia', 'continent_Central_America', 'continent_Europe',\n",
       "       'continent_North_America', 'continent_Oceania',\n",
       "       'continent_South_America'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Model Selection and Training***\n",
    "\n",
    "In this section, we evaluate three different regression models to predict countries' happiness scores based on the available socioeconomic and continental variables. Each model offers different advantages and approaches to address our prediction problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Lineal Regression**\n",
    "\n",
    "We start with a simple linear regression model, which assumes a linear relationship between the independent variables and the target variable.\n",
    "\n",
    "**Results:**\n",
    "\n",
    "- **Mean Squared Error (MSE)**: 0.2109\n",
    "- **Coefficient of Determination (R²)**: 0.8333\n",
    "\n",
    "The linear regression model explains approximately 83% of the variance in the happiness scores, indicating a good fit. However, there is room for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for Linear Regression:  0.21087396980793913\n",
      "R2 Score for Linear Regression:  0.8332893378421595\n"
     ]
    }
   ],
   "source": [
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lf = lr_model.predict(X_test)\n",
    "\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lf)\n",
    "r2_lr = r2_score(y_test, y_pred_lf)\n",
    "\n",
    "print(\"Mean Squared Error for Linear Regression: \", mse_lr)\n",
    "print(\"R2 Score for Linear Regression: \", r2_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Random Forest Regressor**\n",
    "\n",
    "Next, we use a Random Forest Regressor, which is an ensemble model that builds multiple decision trees and merges them to get more accurate and stable predictions.\n",
    "\n",
    "**Results:**\n",
    "\n",
    "- **Mean Squared Error (MSE)**: 0.1700\n",
    "- **Coefficient of Determination (R²)**: 0.8656\n",
    "\n",
    "The Random Forest model achieves a lower MSE and a higher R² score compared to the linear regression, explaining about 86% of the variance. This indicates that the model captures non-linear relationships better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for Random Forest:  0.17005002768093916\n",
      "R2 Score for Random Forest:  0.865563527160472\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators=50, random_state=200)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"Mean Squared Error for Random Forest: \", mse_rf)\n",
    "print(\"R2 Score for Random Forest: \", r2_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Gradient Boosting Regressor**\n",
    "\n",
    "Finally, we implement a Gradient Boosting Regressor, an ensemble model that builds trees sequentially, each attempting to correct the errors of the previous one.\n",
    "\n",
    "**Results:**\n",
    "\n",
    "- **Mean Squared Error (MSE)**: 0.1702\n",
    "- **Coefficient of Determination (R²)**: 0.8655\n",
    "\n",
    "The Gradient Boosting model performs similarly to the Random Forest, with a slightly higher MSE and a similar R² score. This suggests that both ensemble methods are effective in modeling the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for Gradient Boosting:  0.17144932369572535\n",
      "R2 Score for Gradient Boosting:  0.8644572855252797\n"
     ]
    }
   ],
   "source": [
    "gb_model = GradientBoostingRegressor()\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
    "r2_gb = r2_score(y_test, y_pred_gb)\n",
    "\n",
    "print(\"Mean Squared Error for Gradient Boosting: \", mse_gb)\n",
    "print(\"R2 Score for Gradient Boosting: \", r2_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Conclusions**\n",
    "\n",
    "- Both ensemble models (Random Forest and Gradient Boosting) outperform the linear regression model, indicating the presence of non-linear relationships in the data.\n",
    "\n",
    "- The Random Forest Regressor slightly outperforms the Gradient Boosting Regressor in this case.\n",
    "\n",
    "- The Random Forest (RF) model will be saved for future predictions due to its better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Saving the RF model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model/rf_model.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rf_model, \"./model/rf_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etl-workshop-3-OXvWCWU5-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
